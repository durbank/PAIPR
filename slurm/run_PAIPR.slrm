#!/bin/bash
#SBATCH --time=06:00:00 # walltime, abbreviated by -t
#SBATCH --nodes=1      # number of cluster nodes, abbreviated by -N
#SBATCH -o slurm-%j.out-%N # name of the stdout, using the job number (%j) and the first node (%N)
#SBATCH --ntasks=1    # number of MPI tasks, abbreviated by -n
# #SBATCH --constraint="c20"
#SBATCH --mem=256G
# additional information for allocated clusters
#SBATCH --account=rupper     # account - abbreviated by -A
#SBATCH --partition=lonepeak  # partition, abbreviated by -p
#SBATCH --mail-type=FAIL,BEGIN,END
#SBATCH --mail-user=durban.keeler@gmail.com

# Purge old modules and load required ones
module purge
module load matlab
module load rclone

# Define current working directory
startDIR=$(pwd)

# Define path to primary MATLAB processing script
SRCFILE="/uufs/chpc.utah.edu/common/home/u1046484/Codebase/PAIPR/src/scripts/process_HPC.m"
# directory with the Matlab functions required to run primary script
SRCDIR="/uufs/chpc.utah.edu/common/home/u1046484/Codebase/PAIPR/src/"
# directory to output results
OUTDIR=$startDIR

# Assign scratch directory to process data
SCRDIR="/scratch/general/nfs1/u1046484/"
# SCRDIR="/scratch/general/lustre/u1046484/"

# make scratch dir, copy input data there and cd to it
mkdir -p $SCRDIR #should already exist from dataDMZ.sh
cp $SRCFILE $SCRDIR
cp -r $SRCDIR $SCRDIR/src
cd $SCRDIR

# Create seperate directory within scratch to store outputs
mkdir -p Outputs/

# run matlab program with variable options
matlab -nodisplay -r "process_HPC" -logfile Outputs/matlab_stdout.log

# Determine is matlab completed cleanly or with errors
if [[ $? == 0 ]]
then
    # copy results from scratch to the results dir
    cp -r Outputs/ $OUTDIR

    # Return to start dir
    cd $startDIR

    # Clean scratch
    rm -rf $SCRDIR
else
    echo "MATLAB exited due to an unknown error"
    cd $startDIR
fi
